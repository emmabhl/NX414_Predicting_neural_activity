{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NX-414: Brain-like computation and intelligence\n",
    "##### TA: Alessandro Marin Vargas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model usage - Mini projects (Predicting neural activity)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_it_data\n",
    "import torch\n",
    "from torchvision.models import ResNet, resnet50, ResNet50_Weights\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '' ## Insert the folder where the data is, if you download in the same folder as this notebook then leave it blank\n",
    "\n",
    "stimulus_train, stimulus_val, stimulus_test, objects_train, objects_val, objects_test, spikes_train, spikes_val = load_it_data(path_to_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the models\n",
    "Load the models that have been saved in joblib format (and add the function that extract the activations to the ResNet model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torch.load('resnet50_finetuned.pt')\n",
    "pca = joblib.load('pca_layer3.joblib')\n",
    "ridge = joblib.load('ridge_layer3.joblib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the activations from the finetuned ResNet model\n",
    "Define the function that extract the activations from the layer 3 and add it to the ResNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and reshape the model\n",
    "num_classes = len(np.unique(objects_train))\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "params_to_update = model.parameters()\n",
    "model.load_state_dict(torch.load('resnet50_finetuned.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(self, stimuli) :\n",
    "    \"\"\"extract the activations of the model for the given stimuli\n",
    "\n",
    "    Args:\n",
    "        model (model): model we want to extract the activations from\n",
    "        stimuli (ndarray): input data of the processed image's pixels\n",
    "\n",
    "    Returns:\n",
    "        list of ndarray: list of activations for each stimulus\n",
    "    \"\"\"    \n",
    "    activations = []\n",
    "    for x in stimuli : \n",
    "        x = self.conv1(x.unsqueeze(0))\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)        \n",
    "        x = self.layer3(x)\n",
    "        activations.append(torch.flatten(x.squeeze(0)).detach().cpu().numpy())\n",
    "    return activations\n",
    "\n",
    "ResNet.extract_activations = extract_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_val = model.extract_activations(torch.tensor(stimulus_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the 1000 PCs from the activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_val = pca.transform(activations_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ridge.predict(activations_val)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "698955d2a440f09c139f7b7d2bd7d8c99823f6917bcec6f9238f0f39f5a39694"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
