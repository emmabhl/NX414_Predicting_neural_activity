{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503d1e28-d0a8-4ddc-9374-bed9255bc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_it_data, visualize_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import explained_variance_score, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torchvision.models import ResNet, resnet50, ResNet50_Weights\n",
    "import pickle\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79b99b3-fc02-4c70-bd00-023be24537d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '' ## Insert the folder where the data is, if you download in the same folder as this notebook then leave it blank\n",
    "\n",
    "stimulus_train, stimulus_val, stimulus_test, objects_train, objects_val, objects_test, spikes_train, spikes_val = load_it_data(path_to_data)\n",
    "\n",
    "layers = [\"conv1\", \"layer1\", \"layer2\", \"layer3\", \"layer4\", \"avgpool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c4f6cd-e7cb-4018-a364-84f9393cd7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA(layer, n_components = 1000) :\n",
    "    \"\"\"apply PCA on the activations of a layer\n",
    "\n",
    "    Args:\n",
    "        layer_file (string): name of the layer where the activations data are extracted\n",
    "        n_components (int): number of components we want to keep\n",
    "\n",
    "    Returns:\n",
    "        activations: computed PC from the activations\n",
    "    \"\"\"\n",
    "    file_name = layer +'.csv'\n",
    "    activations = np.loadtxt(file_name, delimiter=\",\")\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_activations = pca.fit_transform(activations)\n",
    "    \n",
    "    pca_file = layer +'_pca.csv'\n",
    "    np.savetxt(pca_file, reduced_activations, delimiter=\",\")    \n",
    "    return reduced_activations\n",
    "\n",
    "def extract_activation(self, stimuli: Tensor) :\n",
    "    \"\"\"extract the activations of the model for the given stimuli and layer\n",
    "\n",
    "    Args:\n",
    "        model (model): model we want to extract the activations from\n",
    "        stimuli (ndarray): input data of the processed image's pixels\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary containing the activations for each layer of the model\n",
    "    \"\"\"\n",
    "    import os\n",
    "    for layer in layers :\n",
    "        file_name = layer + '.csv'\n",
    "        if os.path.exists(file_name): os.remove(file_name)\n",
    "        n_stim = stimuli.size(dim=0)\n",
    "        \n",
    "    for x in tqdm(stimuli) : \n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        with open('conv1.csv', 'a', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(torch.flatten(x.squeeze(0)).detach().numpy())\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        with open('layer1.csv', 'a', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(torch.flatten(x.squeeze(0)).detach().numpy())\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        with open('layer2.csv', 'a', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(torch.flatten(x.squeeze(0)).detach().numpy())\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        with open('layer3.csv', 'a', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(torch.flatten(x.squeeze(0)).detach().numpy())      \n",
    "            \n",
    "        x = self.layer4(x)\n",
    "        with open('layer4.csv', 'a', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(torch.flatten(x.squeeze(0)).detach().numpy())        \n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        with open('avgpool.csv', 'a', encoding='UTF8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(torch.flatten(x.squeeze(0)).detach().numpy())        \n",
    "    \n",
    "ResNet.extract_activation = extract_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ed9e687-92aa-4fd6-ae49-cfb77bc8a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the pre-trained ResNet50 model\n",
    "stimuli = torch.tensor(stimulus_train)\n",
    "neural_activity = spikes_train\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights) # include_top = False?\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f3aba99-dba9-4912-9a60-f567e43fc5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the stimuli\n",
    "preprocess = weights.transforms()\n",
    "img_transformed = preprocess(stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8081d9-d215-43b8-b67d-b4af94cf02e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no file\n",
      "no file\n",
      "no file\n",
      "no file\n",
      "no file\n",
      "no file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2592/2592 [43:54<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract the activations of the layers\n",
    "activations = model.extract_activation(img_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c82b8-183a-4bf2-af80-24b00b73553c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1\n"
     ]
    }
   ],
   "source": [
    "# compute the 1000 first PCs\n",
    "for layer in tqdm(layers) : \n",
    "    print(layer)\n",
    "    print(apply_PCA(layer).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de86bd-1195-4a28-bdb6-d2cb4c3b895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_alpha_Ridge(X, y, alphas):\n",
    "    \"\"\"implement cross validation to find the best alpha for Ridge regression\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): input data\n",
    "        y (ndarray): output data, neuronal activity\n",
    "        alphas (list of double): list of alpha to test\n",
    "\n",
    "    Returns:\n",
    "        tuple (double, ndarray): best alpha and all the scores for each alpha\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for alpha in alphas:\n",
    "        model = Ridge(alpha=alpha)\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "        scores.append(np.mean(cv_scores))\n",
    "    return alphas[np.argmax(scores)], scores\n",
    "\n",
    "def plot_RidgeCV(alphas, scores):\n",
    "    \"\"\"plot the scores for each alpha\n",
    "\n",
    "    Args:\n",
    "        alphas (list of double): list of alpha that were tested\n",
    "        scores (list of double): list of scores for each alpha\n",
    "    \"\"\"\n",
    "    plt.plot(alphas, scores)\n",
    "    plt.xlabel('alpha')\n",
    "    plt.ylabel('score')\n",
    "    plt.show()\n",
    "    \n",
    "def RidgeCV(X, y, alphas):\n",
    "    \"\"\"find the best alpha for Ridge regression and plot the scores for each alpha, then fit the model with the best alpha\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): input data\n",
    "        y (ndarray): output data, neuronal activity\n",
    "        alphas (list of double): list of alpha to test\n",
    "\n",
    "    Returns:\n",
    "        tuple (model, double): the ridge model fitted with the best alpha and the corresponding alpha\n",
    "    \"\"\"\n",
    "    best_alpha, scores = best_alpha_Ridge(X, y, alphas)\n",
    "    plot_RidgeCV(alphas, scores)\n",
    "    model = Ridge(alpha=best_alpha)\n",
    "    model.fit(X, y)\n",
    "    return model, best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88510a96-0220-4a54-bca0-8c9bf0cef244",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = np.loadtxt(\"conv1.csv\", delimiter=\",\") #, dtype=str)\n",
    "print(activations.shape)\n",
    "\n",
    "alphas = [100000000, 500000000, 1000000000]\n",
    "ridge_model, best_alpha = RidgeCV(activations, spikes_train, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078f6b4-8339-4cce-980e-6ae1f7b92fff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
